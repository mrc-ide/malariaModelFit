---
title: "check_equilibrium"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This package contains two sets of code for returning the equilibrium solution to the Griffin et al. 2014 transmission model. The first was written in R by Jamie Griffin, and the second was written in Rcpp by Xiaoyu Li, before being adapted into the malariaModelFit package by Bob Verity. Here we will compare both sets of code to establish 1) that both sets of code produce the same results, 2) which code set is faster and by how much.

## Install package

Start by installing and loading the package. Run the following lines, uncommenting the first line and replacing `my_token` with your personal Github personal access token (this is required as the package is currently private).

```{r}
# install_github("mrc-ide/malariaModelFit", auth_token=my_token)
library(malariaModelFit)
```

## Compare solutions

Required inputs when determining the equilibrium solution include; entomological innoculation rate (EIR), treatment coverage (ft), a vector of parameters (p), the age distribution of the population (age), and Gaussian quadrature parameters capturing biting heterogeneity (h). We will fix age and biting heterogeneity and draw `n` random values for the other inputs.

```{r}
n <- 1e2 # number of random inputs to explore

age <- default_age()
h <- statmod::gauss.quad.prob(9, dist="normal")
EIR <- runif(n,1,100)
ft <- runif(n)
p <- random_parameters(n)
```

Now calculate equilibrium solution under both methods, and check that results are equal using `all.equal`, which checks for "near equality".

```{r}
is_equal <- rep(NA,n)
for (i in 1:n) {
  eq1 <- human_equilibrium(EIR=EIR[i], ft=ft[i], p=p[[i]], age=age, h=h)
  eq2 <- human_equilibrium_fast(EIR=EIR[i], ft=ft[i], p=p[[i]], age=age, h$nodes, h$weights)
  is_equal[i] <- all.equal(eq1,eq2)
}

# check that results match
if (all(is_equal)) {
  cat("Good news - solutions match exactly!\n")
} else {
  warning("Solutions do not match")
}
```

Hopefully you got good news when running the above, otherwise check your code for bugs!


## Compare speed

We will compare speed with the `microbenchmark` package. Here we compare evaluation time for each of the `n` parameter sets generated above, repeating the evaluation `repeats` times in each case. Overall results are stored in the list `res`, and the median over repeats is stored in the matrix `res_median`.

```{r}
library(microbenchmark)

repeats <- 1  # number of times to repeat evaluation for each parameter set

# loop over parameter sets
res <- NULL
res_median <- matrix(NA,n,2)
for (i in 1:n) {
  
  # benchmark functions
  res_i <- microbenchmark(
    human_equilibrium(EIR=EIR[i], ft=ft[i], p=p[[i]], age=age, h=h),
    human_equilibrium_fast(EIR=EIR[i], ft=ft[i], p=p[[i]], age=age, h$nodes, h$weights),
    times=repeats
  )
  
  # store results
  res$expr <- c(res$expr, res_i$expr)
  res$time <- c(res$time, res_i$time)
  res_median[i,] <- summary(res_i)$median
}
```

We can now produce a box-plot over all results:

```{r}
functionNames <- c("human_equilibrium","human_equilibrium_fast")
boxplot(split(res$time, f=res$expr), names=functionNames, ylab="evaluation time")
```

or we can dig deeper into timings by plotting evaluation time against EIR or treatment rate:

```{r}
# plot evalutation time against EIR
plot_nice1(x=EIR, list(res_median[,1], y=res_median[,2]), col=list(2,3), pch=20, 
           ylab="evaluation time", main="evaluation time against EIR", legend=TRUE,
           legend_title="Function", legend_label=functionNames)

# plot evalutation time against treatment rate
plot_nice1(x=ft, list(res_median[,1], y=res_median[,2]), col=list(2,3), pch=20, 
           ylab="evaluation time", main="evaluation time against treatment rate", 
           legend=TRUE, legend_title="Function", legend_label=functionNames)
```



(Rmarkdown last evaluated: `r format(Sys.time(), '%d %B, %Y')`)
(Rmarkdown last evaluated: `r Sys.time()`)